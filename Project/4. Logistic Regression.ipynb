{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "gFNkv13PBjna"
   },
   "outputs": [],
   "source": [
    "# import general libraries & data preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import different models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# import evaluation metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# import model tuning methods\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n",
    "import hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuemBimSBjne"
   },
   "source": [
    "## 0. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  cardio  \\\n",
       "0   72       1    110     80            1     1      0     0       1       0   \n",
       "1   67       0    140     90            3     1      0     0       1       1   \n",
       "2   71       0    130     70            3     1      0     0       0       1   \n",
       "3   74       1    150    100            1     1      0     0       1       1   \n",
       "4   75       0    100     60            1     1      0     0       0       0   \n",
       "\n",
       "      BMI  \n",
       "0  21.967  \n",
       "1  34.928  \n",
       "2  23.508  \n",
       "3  28.710  \n",
       "4  23.011  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from csv file\n",
    "df = pd.read_csv('cardio_train_cleaned.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into variables and label\n",
    "X = df.drop('cardio', axis=1)\n",
    "y = df['cardio']\n",
    "\n",
    "# scaling with StandardScalar\n",
    "standardScaler = StandardScaler() \n",
    "X_norm = standardScaler.fit_transform(X)\n",
    "\n",
    "# split data into train and validation and test\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X_norm,y, train_size=0.8, stratify=y, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5, stratify=y_rem, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7250313221233103                                                                                                     \n",
      "{'C': 9.123905186454783, 'intercept_scaling': 0.2245817498152391, 'solver': 'liblinear'}                               \n",
      "0.7248831739751622                                                                                                     \n",
      "{'C': 1.3146961170846343, 'intercept_scaling': 1.3003300925505725, 'solver': 'lbfgs'}                                  \n",
      "0.7251796900758325                                                                                                     \n",
      "{'C': 2.0624295903392547, 'intercept_scaling': 0.11267906904729524, 'solver': 'sag'}                                   \n",
      "0.7250313221233103                                                                                                     \n",
      "{'C': 1.0487412824295712, 'intercept_scaling': 1.5647593294147564, 'solver': 'liblinear'}                              \n",
      "0.7250313221233103                                                                                                     \n",
      "{'C': 3.248345988276611, 'intercept_scaling': 0.45551785744496165, 'solver': 'lbfgs'}                                  \n",
      "0.7250313221233103                                                                                                     \n",
      "{'C': 0.9896540256554588, 'intercept_scaling': 0.5161050778862608, 'solver': 'saga'}                                   \n",
      "0.7251796900758325                                                                                                     \n",
      "{'C': 1.789540844130973, 'intercept_scaling': 0.08052956431718374, 'solver': 'lbfgs'}                                  \n",
      "0.7250313221233103                                                                                                     \n",
      "{'C': 0.5641186178324836, 'intercept_scaling': 1.5530625597084895, 'solver': 'lbfgs'}                                  \n",
      "0.7248827343664138                                                                                                     \n",
      "{'C': 0.29024761887919565, 'intercept_scaling': 0.31826146091445756, 'solver': 'liblinear'}                            \n",
      "0.7248831739751622                                                                                                     \n",
      "{'C': 1.3066304266946962, 'intercept_scaling': 0.46150813682711206, 'solver': 'liblinear'}                             \n",
      "100%|███████████████████████████████████████████████| 10/10 [00:01<00:00,  5.13trial/s, best loss: -0.7251796900758325]\n",
      "Best:\n",
      "{'C': 2.0624295903392547, 'intercept_scaling': 0.11267906904729524, 'solver': 2}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning with Hyperopt\n",
    "def objective(search_space):\n",
    "    lr = LogisticRegression(**search_space)\n",
    "    current_score = cross_val_score(lr, X_valid, y_valid, cv=10).mean()\n",
    "    print(current_score, search_space)\n",
    "    return {'loss': -current_score, 'status': STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "            'C': hp.lognormal('C', 0, 1.0),\n",
    "            'intercept_scaling': hp.lognormal('intercept_scaling', 0, 1.0),\n",
    "            'solver': hp.choice('solver', ['liblinear', 'lbfgs','sag', 'saga']),\n",
    "        }\n",
    "\n",
    "best_params = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=10)\n",
    "best_params_base = best_params\n",
    "print('Best:')\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results\n",
      "Accuracy:  0.7278421198925229\n",
      "Precision:  0.7524718424898977\n",
      "Recall:  0.6622025498429993\n",
      "f1_score: 0.7044571888519972\n",
      "\n",
      "Test Results\n",
      "Accuracy:  0.7245775274236584\n",
      "Precision:  0.7476027397260274\n",
      "Recall:  0.6607142857142857\n",
      "f1_score: 0.7014781491002571\n"
     ]
    }
   ],
   "source": [
    "# Get algorithm string as hp.choice only can display the integer\n",
    "solver_dic = {0:'liblinear', 1:'lbfgs', 2:'sag', 3:'saga'}\n",
    "solver = solver_dic[best_params_base['solver']]\n",
    "\n",
    "# fit hyperparamater(Hyperopt) and train data into the model\n",
    "lr = LogisticRegression(C=best_params_base['C'], intercept_scaling=best_params_base['intercept_scaling'], solver=solver)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precision = precision_score(y_train, y_pred_train, average='binary')\n",
    "recall = recall_score(y_train, y_pred_train, average='binary')\n",
    "f1 = f1_score(y_train, y_pred_train, average='binary')\n",
    "\n",
    "print('Train Results')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('f1_score:', f1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test, average='binary')\n",
    "recall = recall_score(y_test, y_pred_test, average='binary')\n",
    "f1 = f1_score(y_test, y_pred_test, average='binary')\n",
    "\n",
    "print('\\nTest Results')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('f1_score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bagging with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725178810858336                                                                                                      \n",
      "{'n_estimators': 245}                                                                                                  \n",
      "0.7253269590064841                                                                                                     \n",
      "{'n_estimators': 99}                                                                                                   \n",
      "0.7244378503132213                                                                                                     \n",
      "{'n_estimators': 126}                                                                                                  \n",
      "0.7244382899219696                                                                                                     \n",
      "{'n_estimators': 850}                                                                                                  \n",
      "0.7251790306627102                                                                                                     \n",
      "{'n_estimators': 302}                                                                                                  \n",
      "0.7254757665677547                                                                                                     \n",
      "{'n_estimators': 177}                                                                                                  \n",
      "0.7248825145620399                                                                                                     \n",
      "{'n_estimators': 564}                                                                                                  \n",
      "0.7254759863721288                                                                                                     \n",
      "{'n_estimators': 338}                                                                                                  \n",
      "0.7251792504670844                                                                                                     \n",
      "{'n_estimators': 968}                                                                                                  \n",
      "0.724735025827014                                                                                                      \n",
      "{'n_estimators': 399}                                                                                                  \n",
      "100%|██████████████████████████████████████████████| 10/10 [34:46<00:00, 208.61s/trial, best loss: -0.7254759863721288]\n",
      "Best:\n",
      "{'n_estimators': 337}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning with Hyperopt\n",
    "def objective(search_space):\n",
    "    lr = LogisticRegression(C=best_params_base['C'], intercept_scaling=best_params_base['intercept_scaling'], solver=solver)\n",
    "    clf = BaggingClassifier(**search_space, base_estimator=lr)\n",
    "    current_score = cross_val_score(clf, X_valid, y_valid, cv=10).mean()\n",
    "    print(current_score, search_space)\n",
    "    return {'loss': -current_score, 'status': STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(1, 1000))\n",
    "        }\n",
    "\n",
    "best_params = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=10)\n",
    "print('Best:')\n",
    "print(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results\n",
      "Accuracy:  0.7278050588344297\n",
      "Precision:  0.7524505588993982\n",
      "Recall:  0.662126886845988\n",
      "f1_score: 0.7044050469885095\n",
      "\n",
      "Test Results\n",
      "Accuracy:  0.7244292914319597\n",
      "Precision:  0.7471775573041396\n",
      "Recall:  0.6610169491525424\n",
      "f1_score: 0.7014613778705637\n"
     ]
    }
   ],
   "source": [
    "# fit hyperparamater(Hyperopt) and train data into the model\n",
    "lr = LogisticRegression(C=best_params_base['C'], intercept_scaling=best_params_base['intercept_scaling'], solver=solver)\n",
    "clf = BaggingClassifier(base_estimator=lr, n_estimators=best_params['n_estimators'], random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precision = precision_score(y_train, y_pred_train, average='binary')\n",
    "recall = recall_score(y_train, y_pred_train, average='binary')\n",
    "f1 = f1_score(y_train, y_pred_train, average='binary')\n",
    "\n",
    "print('Train Results')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('f1_score:', f1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test, average='binary')\n",
    "recall = recall_score(y_test, y_pred_test, average='binary')\n",
    "f1 = f1_score(y_test, y_pred_test, average='binary')\n",
    "\n",
    "print('\\nTest Results')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('f1_score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AdaBoost with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7225090669304319                                                                                                     \n",
      "{'algorithm': 'SAMME', 'learning_rate': 0.0425, 'n_estimators': 194}                                                   \n",
      "0.7250319815364326                                                                                                     \n",
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.0369, 'n_estimators': 776}                                                 \n",
      "0.7245868776788658                                                                                                     \n",
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.02, 'n_estimators': 606}                                                   \n",
      "0.723845917133751                                                                                                      \n",
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.0115, 'n_estimators': 414}                                                 \n",
      "0.7239942850862732                                                                                                     \n",
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.013600000000000001, 'n_estimators': 508}                                   \n",
      "0.7204358720738543                                                                                                     \n",
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.003, 'n_estimators': 135}                                                  \n",
      "0.7228082206835917                                                                                                     \n",
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.008400000000000001, 'n_estimators': 279}                                   \n",
      "0.7235491812287064                                                                                                     \n",
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.009600000000000001, 'n_estimators': 978}                                   \n",
      "0.7232489284536763                                                                                                     \n",
      "{'algorithm': 'SAMME', 'learning_rate': 0.0216, 'n_estimators': 770}                                                   \n",
      "0.7226600725354435                                                                                                     \n",
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.006500000000000001, 'n_estimators': 325}                                   \n",
      "100%|███████████████████████████████████████████████| 10/10 [07:21<00:00, 44.11s/trial, best loss: -0.7250319815364326]\n",
      "Best:\n",
      "{'algorithm': 0, 'learning_rate': 0.0369, 'n_estimators': 726}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning with Hyperopt\n",
    "def objective(search_space):\n",
    "    lr = LogisticRegression(C=best_params_base['C'], intercept_scaling=best_params_base['intercept_scaling'], solver=solver)\n",
    "    clf = AdaBoostClassifier(**search_space, base_estimator=lr)\n",
    "    current_score = cross_val_score(clf, X_valid, y_valid, cv=10).mean()\n",
    "    print(current_score, search_space)\n",
    "    return {'loss': -current_score, 'status': STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(50, 1000)),\n",
    "            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n",
    "            'algorithm': hp.choice('algorithm', ['SAMME.R','SAMME'])\n",
    "        }\n",
    "\n",
    "best_params = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=10)\n",
    "print('Best:')\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results\n",
      "Accuracy:  0.7256184564069305\n",
      "Precision:  0.7277285904567892\n",
      "Recall:  0.7027579162410623\n",
      "f1_score: 0.7150253084162513\n",
      "\n",
      "Test Results\n",
      "Accuracy:  0.718055143788912\n",
      "Precision:  0.7209962168978562\n",
      "Recall:  0.6921912832929782\n",
      "f1_score: 0.7063001852995676\n"
     ]
    }
   ],
   "source": [
    "# Get algorithm string as hp.choice only can display the integer\n",
    "algo_dic = {0:'SAMME', 1:'SAMME.R'}\n",
    "algo = algo_dic[best_params['algorithm']]\n",
    "\n",
    "# fit hyperparamater(Hyperopt) and train data into the model\n",
    "clf = AdaBoostClassifier(base_estimator=lr, n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], algorithm=algo)\n",
    "model = clf.fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precision = precision_score(y_train, y_pred_train, average='binary')\n",
    "recall = recall_score(y_train, y_pred_train, average='binary')\n",
    "f1 = f1_score(y_train, y_pred_train, average='binary')\n",
    "\n",
    "print('Train Results')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('f1_score:', f1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test, average='binary')\n",
    "recall = recall_score(y_test, y_pred_test, average='binary')\n",
    "f1 = f1_score(y_test, y_pred_test, average='binary')\n",
    "\n",
    "print('\\nTest Results')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('f1_score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All metrics decrease slighly for AdaBoost compared to base estimator"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
